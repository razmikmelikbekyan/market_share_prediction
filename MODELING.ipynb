{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Feature Engineering\n",
    "\n",
    "We will add some more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.special import inv_boxcox, boxcox1p\n",
    "\n",
    "# supress unnecessary warnings for readability and cleaner presentation\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function which performs all steps of data processing which we applied during \n",
    "# Data cleaning and preprocessing\n",
    "def read_clean_data():\n",
    "    \n",
    "    # reading data\n",
    "    df_train = pd.read_csv('use_case_data.csv')\n",
    "    df_score = pd.read_csv('score_data.csv')\n",
    "\n",
    "    df_train['data_type'] = 'train'\n",
    "    df_score['data_type'] = 'score'\n",
    "    \n",
    "    # removing negative market shares\n",
    "    temp = df_train[df_train['Market_Share'] >= 0]\n",
    "    \n",
    "    # applying boxcox\n",
    "    market_share = stats.boxcox(temp['Market_Share'].values + 1e-30, lmbda=0.25)\n",
    "    \n",
    "    # combining train and score\n",
    "    data = pd.concat([temp.drop(columns='Market_Share'), df_score],ignore_index=True)\n",
    "    \n",
    "    # adding response variable\n",
    "    data['Market_Share'] = np.nan\n",
    "    mask = data['data_type'] == 'train'\n",
    "    data.loc[mask, 'Market_Share'] = market_share\n",
    "    data.drop(columns='data_type', inplace=True)\n",
    "    \n",
    "    # changing dtype to category\n",
    "    data['ITEMSCODE'] = data['ITEMSCODE'].astype('category')\n",
    "\n",
    "    # spliting to year and month, adding to not_useful_features list\n",
    "    data['LAUNCH_YEAR'], data['LAUNCH_MONTH'] = data['NPLLAUNCHDATE'].map(str).apply(lambda x: [x[:4], x[4:]]).str   \n",
    "    \n",
    "    # removing not useful features\n",
    "    not_useful = ['BRMID', 'LATESTPERIODINDEX', 'NPLLAUNCHDATE', 'ISREPLACEMENT', 'BRM', 'MARKETEDBRAND',\n",
    "                  'BRANDSUBFAMILY', 'NPLLAUNCHYEAR', 'RTYPE', 'ITEMSHAPE']\n",
    "    \n",
    "    data.drop(columns=not_useful, inplace=True)\n",
    "    \n",
    "    # filling missing values\n",
    "    data['SPECIALFLAVOR'].fillna('NOSPECIALFLAVOR', inplace=True)\n",
    "    data['TIPCOLOR'].fillna('NOTIPCOLOR', inplace=True)\n",
    "    \n",
    "    # transform categorical features into the appropriate type\n",
    "    for c in data.columns:\n",
    "        col_type = data[c].dtype\n",
    "        if col_type == 'object' or col_type.name == 'category':\n",
    "            data[c] = data[c].astype('category')\n",
    "            \n",
    "    # transforming with boxcox1p for reducing skew\n",
    "    data[['LEN', 'NCON', 'RETAILPACKPRICE']] = boxcox1p(data[['LEN', 'NCON', 'RETAILPACKPRICE']], -0.25)\n",
    "\n",
    "    print('all data shape: {}'.format(data.shape))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add some more features by aggregating some categorical features by numeric ones.\n",
    "\n",
    "For example, we will calculate **mean, median, std, skew** of **RETAILPACKPRICE** for each **REGION**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(data, f_1, f_2):\n",
    "    \"\"\"Aggregates f_1 by f_2\"\"\"\n",
    "\n",
    "    mean_ = '{}_{}_mean'.format(f_1, f_2)\n",
    "    median_ = '{}_{}_median'.format(f_1, f_2)\n",
    "    std_ = '{}_{}_std'.format(f_1, f_2)\n",
    "    skew_ = '{}_{}_skew'.format(f_1, f_2)\n",
    "    \n",
    "    # aggregation of f_1 by f_2\n",
    "    temp = data.groupby(f_1)[f_2].aggregate({\n",
    "        mean_: np.mean,\n",
    "        std_: np.std,\n",
    "        median_: np.median,\n",
    "        skew_: stats.skew\n",
    "    }).reset_index()\n",
    "    \n",
    "    # filling nans with 0\n",
    "    for x in (mean_, std_, median_, skew_):\n",
    "        temp[x].fillna(0, inplace=True)\n",
    "        \n",
    "    data = data.merge(temp)\n",
    "    \n",
    "    # adding relative (for example product RETAILPACKPRICE / REGION mean RETAILPACKPRICE)\n",
    "    relative_mean_ = '{}_{}_relative_mean'.format(f_1, f_2)\n",
    "    relative_median_ = '{}_{}_relative_median'.format(f_1, f_2)\n",
    "    \n",
    "    def relative(row, f):\n",
    "        f_value, f_2_value = row[f], row[f_2]\n",
    "        if f_value == 0 and f_2_value == 0:\n",
    "            return 1.\n",
    "        elif f_value == 0 and f_2_value != 0:\n",
    "            return -99999\n",
    "        else:\n",
    "            return f_2_value / f_value\n",
    "        \n",
    "#     data[relative_mean_] = data.apply(lambda row: relative(row, mean_), axis=1)\n",
    "    data[relative_median_] = data.apply(lambda row: relative(row, median_), axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(data, to_drop=None, to_aggregate=None, to_dummy=False, cardinality_ratio=1., ):\n",
    "    \"\"\"\n",
    "    Recives cleaned and preprocessed data, add features, high cardinality features and makes one-hot encoding.\n",
    "    \"\"\"\n",
    "    temp = data.copy()\n",
    "\n",
    "    # removing high cardinality categorical features\n",
    "    if cardinality_ratio < 1.:\n",
    "        n = len(temp)\n",
    "        high_cardinalty_features = []\n",
    "        for c in temp.columns:\n",
    "            if temp[c].dtype.name == 'category' and len(temp[c].unique()) / n > cardinality_ratio:\n",
    "                high_cardinalty_features.append(c)\n",
    "        print('Removing {} features, which have high cardinality.'.format(high_cardinalty_features))\n",
    "        temp.drop(columns=high_cardinalty_features, inplace=True)\n",
    "    \n",
    "    # aggergation\n",
    "    numeric_fs = [c for c in temp.columns if temp[c].dtype.name != 'category' and c != 'Market_Share']\n",
    "    for f_1 in to_aggregate:\n",
    "        for f_2 in numeric_fs:\n",
    "            temp = aggregate(temp, f_1, f_2)\n",
    "    \n",
    "    # adding also **2, **3 and **0.5 for LEN and RETAILPACKPRICE\n",
    "    for x in ['LEN', 'RETAILPACKPRICE']:\n",
    "        temp['{}_**2'.format(x)] = temp[x] ** 2\n",
    "        temp['{}_**3'.format(x)] = temp[x] ** 2\n",
    "        temp['{}_**0.5'.format(x)] = np.sqrt(np.abs(temp[x]))        \n",
    "    print('all data shape after features addition: {}'.format(temp.shape))\n",
    "    \n",
    "    # dropping some features\n",
    "    if to_drop:\n",
    "        temp.drop(columns=to_drop, inplace=True)\n",
    "        print('all data shape after features deletion: {}'.format(temp.shape))\n",
    "    \n",
    "\n",
    "    # one-hot encoding for categorical features\n",
    "    if to_dummy:\n",
    "        temp = pd.get_dummies(temp)\n",
    "        print('all data shape after one-hot-encoding: {}'.format(temp.shape))\n",
    "\n",
    "    # splitting into train and score\n",
    "    mask = temp['Market_Share'].notnull()\n",
    "    training_data, score_data = temp[mask], temp[np.invert(mask)]\n",
    "    score_data.drop(columns='Market_Share', inplace=True)\n",
    "    print('training data shape: {}, score data shape: {}'.format(\n",
    "        training_data.shape, score_data.shape))\n",
    "    return training_data, score_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score, r2_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(matrix, classes, cmap=plt.cm.Reds):\n",
    "    \"\"\"This function plots the normalized confusion matrix.\"\"\"\n",
    "    matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(matrix, interpolation='nearest', cmap=cmap)\n",
    "    plt.title('Normalized Confusion matrix', fontsize=17)\n",
    "    cb = plt.colorbar()\n",
    "    cb.ax.tick_params(labelsize=15)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, fontsize=12)\n",
    "    plt.yticks(tick_marks, classes, fontsize=12)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = matrix.max() / 2.\n",
    "    for i, j in itertools.product(range(matrix.shape[0]),range(matrix.shape[1])):\n",
    "        plt.text(j, i, format(matrix[i, j], fmt),\n",
    "                 horizontalalignment=\"center\", fontsize=17,\n",
    "                 color=\"blue\" if matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', fontsize=12)\n",
    "    plt.xlabel('Predicted label', fontsize=12)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_model_performance(y_true, y_pred, matrix):\n",
    "    \"\"\"\n",
    "    This function plots:\n",
    "        - predicted values vs actual values\n",
    "        - confusion matrix\n",
    "        - roc curve\n",
    "    \"\"\"\n",
    "    print()\n",
    "    \n",
    "    # plotting predicted values vs actual ones\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(y_true, y_pred)\n",
    "    plt.title('Actual values vs Predicted values.')\n",
    "    plt.ylabel('Predicted', fontsize=12)\n",
    "    plt.xlabel('Actual', fontsize=12)\n",
    "    plt.show()\n",
    "              \n",
    "    print()\n",
    "    \n",
    "    # plotting confusion matrix\n",
    "    plot_confusion_matrix(matrix, ['Failure', 'Success'])\n",
    "    \n",
    "    print()\n",
    "    threshold = 0.007\n",
    "    threshold_transformed = stats.boxcox(threshold, 0.25)\n",
    "    binary_target = y_true > threshold_transformed\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(binary_target, y_pred)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.plot(fpr, tpr, lw=3, alpha=0.3, label='ROC (AUC = %0.2f)' % (auc_score))\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n",
    "\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.title('ROC curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer(y_true, y_pred):\n",
    "    \"\"\"Calculates differnt merics for evaluating our models.\"\"\"\n",
    "\n",
    "    threshold = 0.007\n",
    "    threshold_transformed = stats.boxcox(threshold, 0.25)\n",
    "\n",
    "    binary_prediction = y_pred > threshold_transformed\n",
    "    binary_target = y_true > threshold_transformed\n",
    "\n",
    "    \"\"\"Regression metrics\"\"\"\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    explained_variance = explained_variance_score(y_true, y_pred)\n",
    "    r_2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    \"\"\"Classification metrics\"\"\"\n",
    "\n",
    "    # The probability that the model ranks a random\n",
    "    # positive example more highly than a random negative example.\n",
    "    auc = roc_auc_score(binary_target, y_pred)\n",
    "\n",
    "    conf_matrix = confusion_matrix(binary_target, binary_prediction)\n",
    "    # true positives (TP): We predicted Y and they do have the disease.\n",
    "    # true negatives (TN): We predicted N, and they don't have the disease.\n",
    "    # false positives (FP): We predicted Y, but they don't have the disease.\n",
    "    # false negatives (FN): We predicted N, but they do have the disease.\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "    # correct labels\n",
    "    total = tn + fp + fn + tp\n",
    "    actual_yes = fn + tp\n",
    "    actual_no = total - actual_yes\n",
    "\n",
    "    # Overall, how often is the classifier correct?\n",
    "    accuracy = (tp + tn) / total\n",
    "\n",
    "    # Overall, how often is it wrong?\n",
    "    misclassification_rate = (fp + fn) / total\n",
    "\n",
    "    # When it is actually Y, how often does it predict Y?\n",
    "    # Probability that a test result will be positive when the disease is present.\n",
    "    # Recall\n",
    "    tp_rate = tp / actual_yes\n",
    "\n",
    "    # When it is actually N, how often does it predict N?\n",
    "    # Probability that a test result will be negative when the disease is not present.\n",
    "    specificity = tn / actual_no\n",
    "\n",
    "    # When it is actually N, how often does it predict Y?\n",
    "    # 1 - specificity\n",
    "    fp_rate = fp / actual_no\n",
    "\n",
    "    # When it predicts Y, how often is it correct?\n",
    "    # Probability that the disease is present when the test is positive.\n",
    "    # Positive Predictive Value or precision\n",
    "    pp_value = tp / (fp + tp)\n",
    "\n",
    "    # When it predicts N, how often is it correct?\n",
    "    # Probability that the disease is not present when the test is negative.\n",
    "    # Negative Predictive Value\n",
    "    np_value = tn / (tn + fn)\n",
    "\n",
    "    # The weighted average of recall and precision.\n",
    "    f_score = 2 * tp_rate * pp_value / (tp_rate + pp_value)\n",
    "\n",
    "    return {\n",
    "        'rmse': rmse,\n",
    "        'explained_variance': explained_variance,\n",
    "        'r_2': r_2,\n",
    "        'confusion_matrix': conf_matrix,\n",
    "        'accuracy': accuracy,\n",
    "        'tpr': tp_rate,\n",
    "        'specificity': specificity,\n",
    "        'fpr': fp_rate,\n",
    "        'ppv': pp_value,\n",
    "        'npv': np_value,\n",
    "        'f_score': f_score,\n",
    "        'auc': auc,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5 fold CV strategy: we will validate our models and tune hyperparameters by 5 fold CV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_mean_score(fold_scores):\n",
    "    \"\"\"Calculates model mean score based on list of each folds scores.\"\"\"\n",
    "    if not fold_scores:\n",
    "        return\n",
    "    keys = list(fold_scores[0].keys())\n",
    "    data = {k: [x[k] for x in fold_scores] for k in keys if k != 'confusion_matrix'}\n",
    "    return {k: (np.mean(v), np.std(v)) for k, v in data.items()}   \n",
    "\n",
    "def cv(model, train_data, train_y, n_folds=5):\n",
    "    \"\"\"Helper function for doing cross validation and collecting metrics.\"\"\"\n",
    "\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    training_metrics, validatin_metrics = [], []\n",
    "    for i, (train_ind, valid_ind) in enumerate(kf.split(train_data)):\n",
    "        model_ = clone(model)\n",
    "        model_.fit(train_data.iloc[train_ind], train_y.iloc[train_ind])\n",
    "\n",
    "        train_y_pred = model_.predict(train_data.iloc[train_ind])\n",
    "        t_metrics = scorer(train_y.iloc[train_ind].values, train_y_pred)\n",
    "\n",
    "        valid_y_pred = model_.predict(train_data.iloc[valid_ind])\n",
    "        v_metrics = scorer(train_y.iloc[valid_ind].values, valid_y_pred)\n",
    "\n",
    "        print('\\nfold: {}\\n'.format(i + 1))\n",
    "        tabular_metrics = [[k, t_metrics[k], v_metrics[k]]\n",
    "                           for k in t_metrics.keys()\n",
    "                           if k != 'confusion_matrix']\n",
    "        \n",
    "        print(tabulate(tabular_metrics,\n",
    "                       headers=['metric_name', 'training_set', 'validation_set'],\n",
    "                       tablefmt=\"fancy_grid\",\n",
    "                       floatfmt=\",.3f\"))\n",
    "\n",
    "        training_metrics.append(t_metrics)\n",
    "        validatin_metrics.append(v_metrics)\n",
    "\n",
    "    mean_t_score = cv_mean_score(training_metrics)\n",
    "    mean_v_score = cv_mean_score(validatin_metrics)\n",
    "\n",
    "    tabular_mean_metrics = [\n",
    "        [k, mean_t_score[k][0], mean_t_score[k][1], mean_v_score[k][0], mean_v_score[k][1]]\n",
    "        for k in mean_t_score.keys()]\n",
    "\n",
    "    tabular_mean_metrics = tabulate(\n",
    "        tabular_mean_metrics,\n",
    "        headers=['metric_name', 'train: mean', 'train: std', 'valid: mean', 'valid: std'],\n",
    "        tablefmt=\"fancy_grid\",\n",
    "        floatfmt=\",.3f\")\n",
    "    return tabular_mean_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data, y, training=True):\n",
    "    \"\"\"Evaluates model on train or test data.\"\"\"\n",
    "    \n",
    "    if training:\n",
    "        # fitting model before prediction\n",
    "        model.fit(data, y)\n",
    "    \n",
    "    # predicition\n",
    "    y_pred = model.predict(data)\n",
    "    \n",
    "    metrics = scorer(y, y_pred)\n",
    "    plot_model_performance(y, y_pred, metrics.pop('confusion_matrix'))\n",
    "    for k, v in metrics.items():\n",
    "        print('{}: {:.3f}'.format(k, v))\n",
    "    \n",
    "    return metrics    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import librairies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparing data: data clening, preprocessing and adding  additional features, one-hot-encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all data shape: (1721, 32)\n"
     ]
    }
   ],
   "source": [
    "df = read_clean_data()\n",
    "\n",
    "# split into numeric and categorical\n",
    "numeric_fs = [c for c in df.columns if df[c].dtype.name != 'category' and c != 'Market_Share']\n",
    "categoircal_fs = list(set(df.columns) - set(numeric_fs) - {'Market_Share'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all data shape after features addition: (1721, 198)\n",
      "all data shape after features deletion: (1721, 193)\n",
      "all data shape after one-hot-encoding: (1721, 517)\n",
      "training data shape: (1692, 517), score data shape: (29, 516)\n"
     ]
    }
   ],
   "source": [
    "# categorical features, which will be aggregated\n",
    "to_aggregate = [\n",
    "    'TCLASS',\n",
    "    'REGION',\n",
    "    'LOCALCLASS',\n",
    "    'BLDIMAGE', \n",
    "    'MARKET',\n",
    "    'MINDICATOR', \n",
    "    'THICATEGORY', \n",
    "    'PCKT',\n",
    "]\n",
    "\n",
    "# categorical features, which will be dropped\n",
    "to_drop = [\n",
    "    'BRANDSUBFAMILYGROUPING', \n",
    "    'BRANDSUBFAMILYLINE',\n",
    "    'BRANDSUBFAMILYGROUP', \n",
    "    'BRANDONMARKET',\n",
    "    'BRANDDIFFERENTIATOR',\n",
    "]\n",
    "\n",
    "training_df, score_df = feature_engineering(df, \n",
    "                                            to_drop=to_drop, \n",
    "                                            to_aggregate=to_aggregate,\n",
    "                                            to_dummy=True, \n",
    "                                            cardinality_ratio=1.)\n",
    "\n",
    "numeric_fs = [c for c in training_df.columns if training_df[c].dtype.name != 'category' and c != 'Market_Share']\n",
    "categoircal_fs = list(set(training_df.columns) - set(numeric_fs) - {'Market_Share'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train - Test split: we will keep 15% of data for final testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1438, 517) (254, 517)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(training_df, test_size=0.15, shuffle=True)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating response variable\n",
    "y_train, X_train = train['Market_Share'], train.drop(columns='Market_Share')\n",
    "y_test, X_test = test['Market_Share'], test.drop(columns='Market_Share')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Base models and their scores on 5 fold CV:**\n",
    "\n",
    "As models we have selected 4 models: Lasso regression, Elastic Net, ExtraTress regression and Gradient tree boosting. First two models are more linear than other two. First 2 models are modifications of linear regession with additional constraints on regression coefficients. The last 2 models are more no-linear models based on decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_scores = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **LASSO Regression :**\n",
    "\n",
    "This model may be very sensitive to outliers. So we need to made it more robust on them. For that we use the sklearn's **Robustscaler()** method on pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fold: 1\n",
      "\n",
      "╒════════════════════╤════════════════╤══════════════════╕\n",
      "│ metric_name        │   training_set │   validation_set │\n",
      "╞════════════════════╪════════════════╪══════════════════╡\n",
      "│ rmse               │          0.208 │            0.290 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ explained_variance │          0.566 │            0.186 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ r_2                │          0.566 │            0.184 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ accuracy           │          0.858 │            0.833 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ tpr                │          0.437 │            0.306 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ specificity        │          0.959 │            0.941 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ fpr                │          0.041 │            0.059 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ ppv                │          0.719 │            0.517 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ npv                │          0.877 │            0.869 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ f_score            │          0.543 │            0.385 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ auc                │          0.884 │            0.754 │\n",
      "╘════════════════════╧════════════════╧══════════════════╛\n",
      "\n",
      "fold: 2\n",
      "\n",
      "╒════════════════════╤════════════════╤══════════════════╕\n",
      "│ metric_name        │   training_set │   validation_set │\n",
      "╞════════════════════╪════════════════╪══════════════════╡\n",
      "│ rmse               │          0.217 │            0.256 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ explained_variance │          0.541 │            0.295 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ r_2                │          0.541 │            0.289 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ accuracy           │          0.857 │            0.837 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ tpr                │          0.387 │            0.348 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ specificity        │          0.971 │            0.930 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ fpr                │          0.029 │            0.070 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ ppv                │          0.763 │            0.485 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ npv                │          0.867 │            0.882 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ f_score            │          0.513 │            0.405 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ auc                │          0.877 │            0.799 │\n",
      "╘════════════════════╧════════════════╧══════════════════╛\n",
      "\n",
      "fold: 3\n",
      "\n",
      "╒════════════════════╤════════════════╤══════════════════╕\n",
      "│ metric_name        │   training_set │   validation_set │\n",
      "╞════════════════════╪════════════════╪══════════════════╡\n",
      "│ rmse               │          0.209 │            0.285 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ explained_variance │          0.567 │            0.166 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ r_2                │          0.567 │            0.165 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ accuracy           │          0.868 │            0.788 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ tpr                │          0.424 │            0.348 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ specificity        │          0.964 │            0.919 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ fpr                │          0.036 │            0.081 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ ppv                │          0.719 │            0.561 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ npv                │          0.885 │            0.826 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ f_score            │          0.534 │            0.430 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ auc                │          0.891 │            0.746 │\n",
      "╘════════════════════╧════════════════╧══════════════════╛\n",
      "\n",
      "fold: 4\n",
      "\n",
      "╒════════════════════╤════════════════╤══════════════════╕\n",
      "│ metric_name        │   training_set │   validation_set │\n",
      "╞════════════════════╪════════════════╪══════════════════╡\n",
      "│ rmse               │          0.211 │            0.268 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ explained_variance │          0.542 │            0.366 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ r_2                │          0.542 │            0.366 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ accuracy           │          0.854 │            0.861 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ tpr                │          0.333 │            0.414 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ specificity        │          0.972 │            0.974 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ fpr                │          0.028 │            0.026 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ ppv                │          0.732 │            0.800 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ npv                │          0.865 │            0.868 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ f_score            │          0.458 │            0.545 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ auc                │          0.878 │            0.839 │\n",
      "╘════════════════════╧════════════════╧══════════════════╛\n",
      "\n",
      "fold: 5\n",
      "\n",
      "╒════════════════════╤════════════════╤══════════════════╕\n",
      "│ metric_name        │   training_set │   validation_set │\n",
      "╞════════════════════╪════════════════╪══════════════════╡\n",
      "│ rmse               │          0.216 │            0.254 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ explained_variance │          0.541 │            0.323 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ r_2                │          0.541 │            0.323 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ accuracy           │          0.861 │            0.840 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ tpr                │          0.411 │            0.346 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ specificity        │          0.967 │            0.949 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ fpr                │          0.033 │            0.051 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ ppv                │          0.744 │            0.600 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ npv                │          0.875 │            0.868 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ f_score            │          0.529 │            0.439 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ auc                │          0.881 │            0.807 │\n",
      "╘════════════════════╧════════════════╧══════════════════╛\n",
      "\n",
      "Lasso score:\n",
      "\n",
      "╒════════════════════╤═══════════════╤══════════════╤═══════════════╤══════════════╕\n",
      "│ metric_name        │   train: mean │   train: std │   valid: mean │   valid: std │\n",
      "╞════════════════════╪═══════════════╪══════════════╪═══════════════╪══════════════╡\n",
      "│ rmse               │         0.212 │        0.004 │         0.271 │        0.015 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ explained_variance │         0.551 │        0.012 │         0.267 │        0.078 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ r_2                │         0.551 │        0.012 │         0.266 │        0.078 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ accuracy           │         0.860 │        0.005 │         0.832 │        0.024 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ tpr                │         0.398 │        0.037 │         0.352 │        0.035 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ specificity        │         0.967 │        0.005 │         0.943 │        0.019 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ fpr                │         0.033 │        0.005 │         0.057 │        0.019 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ ppv                │         0.735 │        0.017 │         0.593 │        0.111 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ npv                │         0.874 │        0.007 │         0.862 │        0.019 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ f_score            │         0.516 │        0.030 │         0.441 │        0.056 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ auc                │         0.882 │        0.005 │         0.789 │        0.035 │\n",
      "╘════════════════════╧═══════════════╧══════════════╧═══════════════╧══════════════╛\n"
     ]
    }
   ],
   "source": [
    "model_lasso = make_pipeline(RobustScaler(), Lasso(alpha=0.0003, max_iter=1e3, tol=1e-5, random_state=1))\n",
    "score = cv(model_lasso, X_train, y_train)\n",
    "all_models_scores['lasso'] = score\n",
    "print('\\nLasso score:\\n')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Elastic Net Regression :**\n",
    "\n",
    "again made robust to outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fold: 1\n",
      "\n",
      "╒════════════════════╤════════════════╤══════════════════╕\n",
      "│ metric_name        │   training_set │   validation_set │\n",
      "╞════════════════════╪════════════════╪══════════════════╡\n",
      "│ rmse               │          0.214 │            0.291 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ explained_variance │          0.541 │            0.182 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ r_2                │          0.541 │            0.181 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ accuracy           │          0.854 │            0.833 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ tpr                │          0.405 │            0.306 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ specificity        │          0.961 │            0.941 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ fpr                │          0.039 │            0.059 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ ppv                │          0.714 │            0.517 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ npv                │          0.871 │            0.869 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ f_score            │          0.517 │            0.385 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ auc                │          0.877 │            0.748 │\n",
      "╘════════════════════╧════════════════╧══════════════════╛\n",
      "\n",
      "fold: 2\n",
      "\n",
      "╒════════════════════╤════════════════╤══════════════════╕\n",
      "│ metric_name        │   training_set │   validation_set │\n",
      "╞════════════════════╪════════════════╪══════════════════╡\n",
      "│ rmse               │          0.223 │            0.255 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ explained_variance │          0.515 │            0.304 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ r_2                │          0.515 │            0.298 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ accuracy           │          0.857 │            0.833 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ tpr                │          0.373 │            0.304 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ specificity        │          0.974 │            0.934 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ fpr                │          0.026 │            0.066 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ ppv                │          0.778 │            0.467 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ npv                │          0.865 │            0.876 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ f_score            │          0.505 │            0.368 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ auc                │          0.869 │            0.798 │\n",
      "╘════════════════════╧════════════════╧══════════════════╛\n",
      "\n",
      "fold: 3\n",
      "\n",
      "╒════════════════════╤════════════════╤══════════════════╕\n",
      "│ metric_name        │   training_set │   validation_set │\n",
      "╞════════════════════╪════════════════╪══════════════════╡\n",
      "│ rmse               │          0.216 │            0.283 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ explained_variance │          0.540 │            0.178 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ r_2                │          0.540 │            0.178 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ accuracy           │          0.869 │            0.792 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ tpr                │          0.410 │            0.318 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ specificity        │          0.968 │            0.932 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ fpr                │          0.032 │            0.068 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ ppv                │          0.737 │            0.583 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ npv                │          0.883 │            0.821 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ f_score            │          0.527 │            0.412 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ auc                │          0.884 │            0.746 │\n",
      "╘════════════════════╧════════════════╧══════════════════╛\n",
      "\n",
      "fold: 4\n",
      "\n",
      "╒════════════════════╤════════════════╤══════════════════╕\n",
      "│ metric_name        │   training_set │   validation_set │\n",
      "╞════════════════════╪════════════════╪══════════════════╡\n",
      "│ rmse               │          0.218 │            0.268 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ explained_variance │          0.512 │            0.368 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ r_2                │          0.512 │            0.368 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ accuracy           │          0.850 │            0.854 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ tpr                │          0.296 │            0.345 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ specificity        │          0.975 │            0.983 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ fpr                │          0.025 │            0.017 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ ppv                │          0.733 │            0.833 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ npv                │          0.859 │            0.856 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ f_score            │          0.421 │            0.488 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ auc                │          0.867 │            0.829 │\n",
      "╘════════════════════╧════════════════╧══════════════════╛\n",
      "\n",
      "fold: 5\n",
      "\n",
      "╒════════════════════╤════════════════╤══════════════════╕\n",
      "│ metric_name        │   training_set │   validation_set │\n",
      "╞════════════════════╪════════════════╪══════════════════╡\n",
      "│ rmse               │          0.223 │            0.255 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ explained_variance │          0.513 │            0.319 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ r_2                │          0.513 │            0.318 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ accuracy           │          0.857 │            0.836 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ tpr                │          0.393 │            0.327 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ specificity        │          0.966 │            0.949 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ fpr                │          0.034 │            0.051 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ ppv                │          0.729 │            0.586 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ npv                │          0.871 │            0.864 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ f_score            │          0.510 │            0.420 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ auc                │          0.873 │            0.804 │\n",
      "╘════════════════════╧════════════════╧══════════════════╛\n",
      "\n",
      "Elastic Net:\n",
      "\n",
      "╒════════════════════╤═══════════════╤══════════════╤═══════════════╤══════════════╕\n",
      "│ metric_name        │   train: mean │   train: std │   valid: mean │   valid: std │\n",
      "╞════════════════════╪═══════════════╪══════════════╪═══════════════╪══════════════╡\n",
      "│ rmse               │         0.219 │        0.004 │         0.270 │        0.015 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ explained_variance │         0.524 │        0.013 │         0.270 │        0.076 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ r_2                │         0.524 │        0.013 │         0.268 │        0.076 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ accuracy           │         0.857 │        0.006 │         0.830 │        0.020 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ tpr                │         0.375 │        0.042 │         0.320 │        0.015 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ specificity        │         0.969 │        0.005 │         0.948 │        0.018 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ fpr                │         0.031 │        0.005 │         0.052 │        0.018 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ ppv                │         0.738 │        0.021 │         0.597 │        0.126 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ npv                │         0.870 │        0.008 │         0.857 │        0.019 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ f_score            │         0.496 │        0.038 │         0.414 │        0.041 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ auc                │         0.874 │        0.006 │         0.785 │        0.033 │\n",
      "╘════════════════════╧═══════════════╧══════════════╧═══════════════╧══════════════╛\n"
     ]
    }
   ],
   "source": [
    "model_enet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=0.8, random_state=3))\n",
    "score = cv(model_enet, X_train, y_train)\n",
    "all_models_scores['elastic_net'] = score\n",
    "print('\\nElastic Net:\\n')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Extra Trees Regressor:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fold: 1\n",
      "\n",
      "╒════════════════════╤════════════════╤══════════════════╕\n",
      "│ metric_name        │   training_set │   validation_set │\n",
      "╞════════════════════╪════════════════╪══════════════════╡\n",
      "│ rmse               │          0.064 │            0.255 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ explained_variance │          0.958 │            0.372 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ r_2                │          0.958 │            0.372 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ accuracy           │          0.977 │            0.844 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ tpr                │          0.928 │            0.306 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ specificity        │          0.989 │            0.954 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ fpr                │          0.011 │            0.046 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ ppv                │          0.954 │            0.577 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ npv                │          0.983 │            0.870 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ f_score            │          0.941 │            0.400 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ auc                │          0.994 │            0.780 │\n",
      "╘════════════════════╧════════════════╧══════════════════╛\n",
      "\n",
      "fold: 2\n",
      "\n",
      "╒════════════════════╤════════════════╤══════════════════╕\n",
      "│ metric_name        │   training_set │   validation_set │\n",
      "╞════════════════════╪════════════════╪══════════════════╡\n",
      "│ rmse               │          0.063 │            0.224 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ explained_variance │          0.961 │            0.456 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ r_2                │          0.961 │            0.454 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ accuracy           │          0.967 │            0.858 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ tpr                │          0.898 │            0.326 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ specificity        │          0.984 │            0.959 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ fpr                │          0.016 │            0.041 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ ppv                │          0.931 │            0.600 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ npv                │          0.975 │            0.882 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ f_score            │          0.914 │            0.423 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ auc                │          0.993 │            0.853 │\n",
      "╘════════════════════╧════════════════╧══════════════════╛\n",
      "\n",
      "fold: 3\n",
      "\n",
      "╒════════════════════╤════════════════╤══════════════════╕\n",
      "│ metric_name        │   training_set │   validation_set │\n",
      "╞════════════════════╪════════════════╪══════════════════╡\n",
      "│ rmse               │          0.063 │            0.267 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ explained_variance │          0.961 │            0.268 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ r_2                │          0.961 │            0.266 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ accuracy           │          0.978 │            0.802 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ tpr                │          0.917 │            0.303 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ specificity        │          0.992 │            0.950 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ fpr                │          0.008 │            0.050 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ ppv                │          0.959 │            0.645 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ npv                │          0.982 │            0.821 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ f_score            │          0.938 │            0.412 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ auc                │          0.996 │            0.791 │\n",
      "╘════════════════════╧════════════════╧══════════════════╛\n",
      "\n",
      "fold: 4\n",
      "\n",
      "╒════════════════════╤════════════════╤══════════════════╕\n",
      "│ metric_name        │   training_set │   validation_set │\n",
      "╞════════════════════╪════════════════╪══════════════════╡\n",
      "│ rmse               │          0.061 │            0.251 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ explained_variance │          0.961 │            0.447 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ r_2                │          0.961 │            0.447 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ accuracy           │          0.969 │            0.847 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ tpr                │          0.883 │            0.483 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ specificity        │          0.988 │            0.939 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ fpr                │          0.012 │            0.061 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ ppv                │          0.945 │            0.667 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ npv                │          0.974 │            0.878 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ f_score            │          0.913 │            0.560 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ auc                │          0.994 │            0.854 │\n",
      "╘════════════════════╧════════════════╧══════════════════╛\n",
      "\n",
      "fold: 5\n",
      "\n",
      "╒════════════════════╤════════════════╤══════════════════╕\n",
      "│ metric_name        │   training_set │   validation_set │\n",
      "╞════════════════════╪════════════════╪══════════════════╡\n",
      "│ rmse               │          0.068 │            0.224 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ explained_variance │          0.955 │            0.471 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ r_2                │          0.955 │            0.471 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ accuracy           │          0.970 │            0.854 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ tpr                │          0.909 │            0.423 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ specificity        │          0.985 │            0.949 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ fpr                │          0.015 │            0.051 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ ppv                │          0.934 │            0.647 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ npv                │          0.979 │            0.881 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ f_score            │          0.921 │            0.512 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ auc                │          0.993 │            0.854 │\n",
      "╘════════════════════╧════════════════╧══════════════════╛\n",
      "\n",
      "ExtraTree:\n",
      "\n",
      "╒════════════════════╤═══════════════╤══════════════╤═══════════════╤══════════════╕\n",
      "│ metric_name        │   train: mean │   train: std │   valid: mean │   valid: std │\n",
      "╞════════════════════╪═══════════════╪══════════════╪═══════════════╪══════════════╡\n",
      "│ rmse               │         0.064 │        0.002 │         0.244 │        0.017 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ explained_variance │         0.959 │        0.003 │         0.403 │        0.076 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ r_2                │         0.959 │        0.003 │         0.402 │        0.076 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ accuracy           │         0.972 │        0.005 │         0.841 │        0.020 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ tpr                │         0.907 │        0.016 │         0.368 │        0.072 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ specificity        │         0.988 │        0.003 │         0.950 │        0.007 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ fpr                │         0.012 │        0.003 │         0.050 │        0.007 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ ppv                │         0.945 │        0.011 │         0.627 │        0.033 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ npv                │         0.979 │        0.004 │         0.866 │        0.023 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ f_score            │         0.925 │        0.012 │         0.461 │        0.063 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ auc                │         0.994 │        0.001 │         0.826 │        0.034 │\n",
      "╘════════════════════╧═══════════════╧══════════════╧═══════════════╧══════════════╛\n"
     ]
    }
   ],
   "source": [
    "model_extratree = ExtraTreesRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=50,\n",
    "    min_samples_split=2, \n",
    "    min_samples_leaf=2,\n",
    "    min_weight_fraction_leaf=0.0002,\n",
    "    max_leaf_nodes=None,\n",
    "    max_features='auto',\n",
    "    min_impurity_decrease=0.00,\n",
    "    n_jobs=2\n",
    "    \n",
    ")\n",
    "\n",
    "score = cv(model_extratree, X_train, y_train)\n",
    "all_models_scores['extra_tree'] = score\n",
    "print('\\nExtraTree:\\n')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **LightGBM :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fold: 1\n",
      "\n",
      "╒════════════════════╤════════════════╤══════════════════╕\n",
      "│ metric_name        │   training_set │   validation_set │\n",
      "╞════════════════════╪════════════════╪══════════════════╡\n",
      "│ rmse               │          0.088 │            0.250 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ explained_variance │          0.923 │            0.393 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ r_2                │          0.923 │            0.393 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ accuracy           │          0.939 │            0.851 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ tpr                │          0.779 │            0.449 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ specificity        │          0.977 │            0.933 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ fpr                │          0.023 │            0.067 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ ppv                │          0.892 │            0.579 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ npv                │          0.949 │            0.892 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ f_score            │          0.832 │            0.506 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ auc                │          0.984 │            0.813 │\n",
      "╘════════════════════╧════════════════╧══════════════════╛\n",
      "\n",
      "fold: 2\n",
      "\n",
      "╒════════════════════╤════════════════╤══════════════════╕\n",
      "│ metric_name        │   training_set │   validation_set │\n",
      "╞════════════════════╪════════════════╪══════════════════╡\n",
      "│ rmse               │          0.087 │            0.229 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ explained_variance │          0.926 │            0.432 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ r_2                │          0.926 │            0.430 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ accuracy           │          0.942 │            0.837 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ tpr                │          0.787 │            0.435 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ specificity        │          0.979 │            0.913 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ fpr                │          0.021 │            0.087 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ ppv                │          0.903 │            0.488 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ npv                │          0.950 │            0.895 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ f_score            │          0.841 │            0.460 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ auc                │          0.984 │            0.834 │\n",
      "╘════════════════════╧════════════════╧══════════════════╛\n",
      "\n",
      "fold: 3\n",
      "\n",
      "╒════════════════════╤════════════════╤══════════════════╕\n",
      "│ metric_name        │   training_set │   validation_set │\n",
      "╞════════════════════╪════════════════╪══════════════════╡\n",
      "│ rmse               │          0.086 │            0.288 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ explained_variance │          0.927 │            0.150 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ r_2                │          0.927 │            0.148 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ accuracy           │          0.950 │            0.812 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ tpr                │          0.810 │            0.379 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ specificity        │          0.980 │            0.941 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ fpr                │          0.020 │            0.059 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ ppv                │          0.897 │            0.658 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ npv                │          0.960 │            0.836 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ f_score            │          0.851 │            0.481 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ auc                │          0.986 │            0.798 │\n",
      "╘════════════════════╧════════════════╧══════════════════╛\n",
      "\n",
      "fold: 4\n",
      "\n",
      "╒════════════════════╤════════════════╤══════════════════╕\n",
      "│ metric_name        │   training_set │   validation_set │\n",
      "╞════════════════════╪════════════════╪══════════════════╡\n",
      "│ rmse               │          0.084 │            0.262 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ explained_variance │          0.927 │            0.398 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ r_2                │          0.927 │            0.398 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ accuracy           │          0.949 │            0.836 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ tpr                │          0.808 │            0.534 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ specificity        │          0.981 │            0.913 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ fpr                │          0.019 │            0.087 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ ppv                │          0.905 │            0.608 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ npv                │          0.957 │            0.886 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ f_score            │          0.854 │            0.569 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ auc                │          0.988 │            0.845 │\n",
      "╘════════════════════╧════════════════╧══════════════════╛\n",
      "\n",
      "fold: 5\n",
      "\n",
      "╒════════════════════╤════════════════╤══════════════════╕\n",
      "│ metric_name        │   training_set │   validation_set │\n",
      "╞════════════════════╪════════════════╪══════════════════╡\n",
      "│ rmse               │          0.089 │            0.227 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ explained_variance │          0.922 │            0.460 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ r_2                │          0.922 │            0.460 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ accuracy           │          0.947 │            0.843 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ tpr                │          0.808 │            0.442 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ specificity        │          0.980 │            0.932 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ fpr                │          0.020 │            0.068 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ ppv                │          0.903 │            0.590 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ npv                │          0.956 │            0.883 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ f_score            │          0.853 │            0.505 │\n",
      "├────────────────────┼────────────────┼──────────────────┤\n",
      "│ auc                │          0.985 │            0.828 │\n",
      "╘════════════════════╧════════════════╧══════════════════╛\n",
      "\n",
      "LGBM:\n",
      "\n",
      "╒════════════════════╤═══════════════╤══════════════╤═══════════════╤══════════════╕\n",
      "│ metric_name        │   train: mean │   train: std │   valid: mean │   valid: std │\n",
      "╞════════════════════╪═══════════════╪══════════════╪═══════════════╪══════════════╡\n",
      "│ rmse               │         0.087 │        0.002 │         0.251 │        0.022 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ explained_variance │         0.925 │        0.002 │         0.367 │        0.111 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ r_2                │         0.925 │        0.002 │         0.366 │        0.111 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ accuracy           │         0.945 │        0.004 │         0.836 │        0.013 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ tpr                │         0.798 │        0.013 │         0.448 │        0.050 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ specificity        │         0.979 │        0.001 │         0.926 │        0.012 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ fpr                │         0.021 │        0.001 │         0.074 │        0.012 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ ppv                │         0.900 │        0.005 │         0.584 │        0.055 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ npv                │         0.954 │        0.004 │         0.878 │        0.022 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ f_score            │         0.846 │        0.009 │         0.504 │        0.037 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ auc                │         0.985 │        0.002 │         0.824 │        0.016 │\n",
      "╘════════════════════╧═══════════════╧══════════════╧═══════════════╧══════════════╛\n"
     ]
    }
   ],
   "source": [
    "model_lgb = lgb.LGBMRegressor(\n",
    "    boosting_type='gbdt',\n",
    "    \n",
    "    objective='rmse',\n",
    "    n_estimators=5000,\n",
    "    learning_rate=0.03,\n",
    "    \n",
    "    max_depth=4,             # Specify the max depth to which tree will grow. \n",
    "    num_leaves=15,             # Number of leaves in one tree\n",
    "\n",
    "    min_child_weight=11,     # minimal sum hessian in one leaf\n",
    "    min_data_in_leaf=20,       # Min number of data in one leaf.\n",
    "    \n",
    "    subsample=0.75,            # Specifies the fraction of data to be used for each iteration\n",
    "    subsample_freq=5,\n",
    "    bagging_seed=9,\n",
    "    \n",
    "    colsample_bytree=0.45,  # Specifies the fraction of features to be taken for each iteration\n",
    "    feature_fraction_seed=7,\n",
    "    \n",
    "    min_gain_to_split=0.01,    # Min gain to perform splitting\n",
    "    reg_alpha=0.00,\n",
    "    reg_lambda=0.,\n",
    "#     max_bin=55,\n",
    "    drop_rate=0.3,\n",
    "    max_drop=50,\n",
    "    \n",
    "    n_jobs=2,\n",
    "    \n",
    ")\n",
    "\n",
    "score = cv(model_lgb, X_train, y_train)\n",
    "all_models_scores['gradient_boosting'] = score\n",
    "print('\\nLGBM:\\n')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MEAN CV scores for each model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " model: lasso mean CV score\n",
      "╒════════════════════╤═══════════════╤══════════════╤═══════════════╤══════════════╕\n",
      "│ metric_name        │   train: mean │   train: std │   valid: mean │   valid: std │\n",
      "╞════════════════════╪═══════════════╪══════════════╪═══════════════╪══════════════╡\n",
      "│ rmse               │         0.212 │        0.004 │         0.271 │        0.015 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ explained_variance │         0.551 │        0.012 │         0.267 │        0.078 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ r_2                │         0.551 │        0.012 │         0.266 │        0.078 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ accuracy           │         0.860 │        0.005 │         0.832 │        0.024 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ tpr                │         0.398 │        0.037 │         0.352 │        0.035 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ specificity        │         0.967 │        0.005 │         0.943 │        0.019 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ fpr                │         0.033 │        0.005 │         0.057 │        0.019 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ ppv                │         0.735 │        0.017 │         0.593 │        0.111 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ npv                │         0.874 │        0.007 │         0.862 │        0.019 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ f_score            │         0.516 │        0.030 │         0.441 │        0.056 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ auc                │         0.882 │        0.005 │         0.789 │        0.035 │\n",
      "╘════════════════════╧═══════════════╧══════════════╧═══════════════╧══════════════╛\n",
      "\n",
      "\n",
      " model: elastic_net mean CV score\n",
      "╒════════════════════╤═══════════════╤══════════════╤═══════════════╤══════════════╕\n",
      "│ metric_name        │   train: mean │   train: std │   valid: mean │   valid: std │\n",
      "╞════════════════════╪═══════════════╪══════════════╪═══════════════╪══════════════╡\n",
      "│ rmse               │         0.219 │        0.004 │         0.270 │        0.015 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ explained_variance │         0.524 │        0.013 │         0.270 │        0.076 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ r_2                │         0.524 │        0.013 │         0.268 │        0.076 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ accuracy           │         0.857 │        0.006 │         0.830 │        0.020 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ tpr                │         0.375 │        0.042 │         0.320 │        0.015 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ specificity        │         0.969 │        0.005 │         0.948 │        0.018 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ fpr                │         0.031 │        0.005 │         0.052 │        0.018 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ ppv                │         0.738 │        0.021 │         0.597 │        0.126 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ npv                │         0.870 │        0.008 │         0.857 │        0.019 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ f_score            │         0.496 │        0.038 │         0.414 │        0.041 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ auc                │         0.874 │        0.006 │         0.785 │        0.033 │\n",
      "╘════════════════════╧═══════════════╧══════════════╧═══════════════╧══════════════╛\n",
      "\n",
      "\n",
      " model: extra_tree mean CV score\n",
      "╒════════════════════╤═══════════════╤══════════════╤═══════════════╤══════════════╕\n",
      "│ metric_name        │   train: mean │   train: std │   valid: mean │   valid: std │\n",
      "╞════════════════════╪═══════════════╪══════════════╪═══════════════╪══════════════╡\n",
      "│ rmse               │         0.064 │        0.002 │         0.244 │        0.017 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ explained_variance │         0.959 │        0.003 │         0.403 │        0.076 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ r_2                │         0.959 │        0.003 │         0.402 │        0.076 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ accuracy           │         0.972 │        0.005 │         0.841 │        0.020 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ tpr                │         0.907 │        0.016 │         0.368 │        0.072 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ specificity        │         0.988 │        0.003 │         0.950 │        0.007 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ fpr                │         0.012 │        0.003 │         0.050 │        0.007 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ ppv                │         0.945 │        0.011 │         0.627 │        0.033 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ npv                │         0.979 │        0.004 │         0.866 │        0.023 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ f_score            │         0.925 │        0.012 │         0.461 │        0.063 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ auc                │         0.994 │        0.001 │         0.826 │        0.034 │\n",
      "╘════════════════════╧═══════════════╧══════════════╧═══════════════╧══════════════╛\n",
      "\n",
      "\n",
      " model: gradient_boosting mean CV score\n",
      "╒════════════════════╤═══════════════╤══════════════╤═══════════════╤══════════════╕\n",
      "│ metric_name        │   train: mean │   train: std │   valid: mean │   valid: std │\n",
      "╞════════════════════╪═══════════════╪══════════════╪═══════════════╪══════════════╡\n",
      "│ rmse               │         0.087 │        0.002 │         0.251 │        0.022 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ explained_variance │         0.925 │        0.002 │         0.367 │        0.111 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ r_2                │         0.925 │        0.002 │         0.366 │        0.111 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ accuracy           │         0.945 │        0.004 │         0.836 │        0.013 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ tpr                │         0.798 │        0.013 │         0.448 │        0.050 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ specificity        │         0.979 │        0.001 │         0.926 │        0.012 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ fpr                │         0.021 │        0.001 │         0.074 │        0.012 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ ppv                │         0.900 │        0.005 │         0.584 │        0.055 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ npv                │         0.954 │        0.004 │         0.878 │        0.022 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ f_score            │         0.846 │        0.009 │         0.504 │        0.037 │\n",
      "├────────────────────┼───────────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ auc                │         0.985 │        0.002 │         0.824 │        0.016 │\n",
      "╘════════════════════╧═══════════════╧══════════════╧═══════════════╧══════════════╛\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in all_models_scores.items():\n",
    "    print('\\n model: {} mean CV score'.format(k))\n",
    "    print(v)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some insights from scores: \n",
    "\n",
    "* As excpected **Lasso** and **ElasticNet** performance are almost similar. Besides this their performance is also low compared to DecisionTree models, which is also expected as we investigated that our data mostly non linear.\n",
    "\n",
    "* If we compare ExtraTrees and GradientBoosting then we can notice that their performances are comparable: mean validation RMSE is almost equal and AUC is almost equal. We see some difference for tpr (true positive ratio - When it is actually Y, how often does it predict Y?) and fpr (false positive ratio - When it is actually N, how often does it predict Y?) metrics for given 0.7% threshold. As we can see both are bigger for GradientBoosting based model (tpr: 0.448 vs 0.368, fpr: 0.074 vs 0.050). So what does it mean? We can assume that GradientBoosting based model learned more from data than ExtraTrees, so it can differentiate more succesful launches, but together with that the false positive ratio is a bit more 2.4%, which is not good from bussiness prospective. So GradientBoosting based models pays fpr increase cost (by 2.4%) for having higher ptr by 8.0%. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-853cfda5f412>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_lgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfeat_imp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_lgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfeat_imp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlargest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'barh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate_model' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_model(model_lgb, X_train, y_train, training=True)\n",
    "feat_imp = pd.Series(model_lgb.feature_importances_, index=X_train.columns)\n",
    "feat_imp.nlargest(30).plot(kind='barh', figsize=(8,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evaluate_model(model_lgb, X_test, y_test, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    evaluate_train_test(model, X_train, y_train, X_test, y_test)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = pd.Series(model_extratree.feature_importances_, index=X_train.columns)\n",
    "feat_imp.nlargest(30).plot(kind='barh', figsize=(8,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feat_imp = pd.Series(model_lgb.feature_importances_, index=X_train.columns)\n",
    "feat_imp.nlargest(30).plot(kind='barh', figsize=(8,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = pd.Series(model_xgb.feature_importances_, index=X_train.columns)\n",
    "feat_imp.nlargest(30).plot(kind='barh', figsize=(8,10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    params = {\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'num_leaves': int(params['num_leaves']),\n",
    "        'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n",
    "        'min_split_gain': '{:.4f}'.format(params['min_split_gain']),\n",
    "        'drop_rate': '{:.4f}'.format(params['drop_rate'])\n",
    "        \n",
    "    }\n",
    "\n",
    "    regressor = lgb.LGBMRegressor(\n",
    "    boosting_type='dart',\n",
    "    \n",
    "    objective='rmse',\n",
    "    n_estimators=5000,\n",
    "    learning_rate=0.3,\n",
    "    \n",
    "#     max_depth=4,             # Specify the max depth to which tree will grow. \n",
    "#     num_leaves=10,             # Number of leaves in one tree\n",
    "\n",
    "    min_child_weight=11,     # minimal sum hessian in one leaf\n",
    "    min_data_in_leaf=20,       # Min number of data in one leaf.\n",
    "    \n",
    "    subsample=0.75,            # Specifies the fraction of data to be used for each iteration\n",
    "    subsample_freq=5,\n",
    "    bagging_seed=9,\n",
    "    \n",
    "#     colsample_bytree=0.45,  # Specifies the fraction of features to be taken for each iteration\n",
    "    feature_fraction_seed=7,\n",
    "    \n",
    "#     min_gain_to_split=0.002,    # Min gain to perform splitting\n",
    "    reg_alpha=0.001,\n",
    "    reg_lambda=0.,\n",
    "#     max_bin=55,\n",
    "#     drop_rate=0.3,\n",
    "    max_drop=50,\n",
    "    \n",
    "    n_jobs=2,\n",
    "    **params\n",
    "    )\n",
    "\n",
    "    score = cv(regressor, X_train, y_train)\n",
    "    \n",
    "    print()\n",
    "    print(params)\n",
    "    print(score)\n",
    "    return float(score.splitlines()[3].split()[-4])\n",
    "\n",
    "\n",
    "space = {\n",
    "    'max_depth': hp.quniform('max_depth', 4, 6, 1),\n",
    "    'num_leaves': hp.quniform('num_leaves', 16, 64, 8),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 0.8),\n",
    "    'min_split_gain': hp.uniform('min_split_gain', 0.0018, 0.0022),\n",
    "    'drop_rate': hp.quniform('drop_rate', 0.2, 0.4, 0.05),\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(score.splitlines()[3].split()[-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best['num_leaves'] = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
